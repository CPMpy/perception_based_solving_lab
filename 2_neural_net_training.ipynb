{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: make sure your environment is setup correctly (see [installation instructions](README.md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network for Perception based solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import lightning as pl\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we will group all hyperparameters invovled with building and training our neural network into a single dict. \n",
    "\n",
    "These hyperparameters will appears in different cells below. Later you will have the opportunity to play around with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for our neural network\n",
    "hyperparams = {\n",
    "    # preprocessing\n",
    "    'size':(300,300),\n",
    "    # architecture\n",
    "    'dropout':0.25,\n",
    "    'batchnorm':True,\n",
    "    'pooling_kernel_size':3,\n",
    "    'pooling_stride':3,\n",
    "    # training\n",
    "    'train_batch_size':1,\n",
    "    'learning_rate':0.001,\n",
    "    'max_total_epochs':5,\n",
    "    'early_stopping_patience':5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T \n",
    "from torchvision.io import read_image\n",
    "\n",
    "base_tsfm = T.Compose([\n",
    "    T.Lambda(lambda img_str:read_image(img_str)),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(hyperparams['size']), # scale down image here to speed up training\n",
    "    T.ToTensor(),\n",
    "    T.Normalize( # Normalize the data (all values between -1 and 1) to improve convergence\n",
    "        mean=[0.5320, 0.5209, 0.5204],\n",
    "        std=[0.1862917, 0.19031495, 0.18998064]\n",
    "    ), \n",
    "    #T.Grayscale(1) # grayscale the image\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = os.path.join('data', 'visual_sudoku', 'img', '059.jpg')\n",
    "original = Image.open(img_path)\n",
    "\n",
    "see_torch_image = T.ToPILImage()\n",
    "image_preprocessed = base_tsfm(img_path)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(6,9))\n",
    "axes[0].imshow(original)\n",
    "axes[0].set_title('original image')\n",
    "# This is what the neural network actually sees\n",
    "axes[1].imshow(see_torch_image(image_preprocessed))\n",
    "axes[1].set_title('preprocessed image')\n",
    "for ax in axes:\n",
    "    ax.set_axis_off()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our neural network, we have to define its architecture. \n",
    "\n",
    "We want to classify multiple cells in an image. Therefore, we will use a convolutional neural network (CNN). \n",
    "\n",
    "More specifically, we take inspiration from previous work to build a 5-layers CNN which takes a full sudoku image as input and provide an 81x10 probability distribution matrix as output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/cnn.png\" alt=\"CNN\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Following best practicies regarding building deep neural network architecutre, we first define helpers function to build this CNN more easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_conv_layers, make_fc_layers_global_pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions helps us to create dense and convolutional layers, by providing a configuration as a list. \n",
    "\n",
    "Our CNN has two components:\n",
    "- Feature extractor: mainly composed of convolutional layers. Extract features from the image by mapping the input to a latent space. \n",
    "- Classifier: global average pooling layer, followed by a softmax layer to output a probability distribution matrix of the desired shape (81 x 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullImageCNN(nn.Module):\n",
    "    \"\"\"Generalized 5-layers CNN, similar to https://github.com/Kyubyong/sudoku or\n",
    "    SudokuNet used in NeurASP.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_shape=(9, 9), n_classes=10) -> None:\n",
    "        super().__init__()\n",
    "        self.grid_shape = grid_shape\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # backbone with 5 convolutional layers\n",
    "        full_image_backbone_config = [\n",
    "            (32, 4, 2, 0),\n",
    "            (64, 3, 2, 0), \n",
    "            (128, 3, 2, 0), \n",
    "            (256, 2, 2, 0), \n",
    "            (512, 2, 2, 0), \n",
    "        ]\n",
    "\n",
    "        conv_layers = make_conv_layers(\n",
    "            full_image_backbone_config, \n",
    "            in_channels=3, # number of channel in the input image (3 for RGB, 1 for grayscale)\n",
    "            p=hyperparams['dropout'], # dropout rate\n",
    "            pool_ks=hyperparams['pooling_kernel_size'], \n",
    "            pool_str=hyperparams['pooling_stride'], \n",
    "            batch_norm=hyperparams['batchnorm'] # controls whether to add batchnorm in-between convolutional layers\n",
    "        )\n",
    "        # because of the last convolutional layer, this backbone output a tensor whose first dimension is of size 512\n",
    "        self.feat_extract = nn.Sequential( *conv_layers)\n",
    "\n",
    "        # classifier\n",
    "        out_layers = make_fc_layers_global_pooling(\n",
    "            in_dim=512, # this should match with the size of first dimension of the previous layer (hence 512)\n",
    "            out_shape=grid_shape, \n",
    "            num_classes=n_classes\n",
    "        )\n",
    "        self.classifier = nn.Sequential(*out_layers,  nn.Softmax(-1))\n",
    "        # the output is of size 81 x 10 \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.feat_extract(x)\n",
    "        return {\n",
    "            'predictions': self.classifier(h)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_cnn = FullImageCNN((9,9), n_classes=10)\n",
    "full_image_cnn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Validate - Test\n",
    "\n",
    "We now split our dataset into a training, a validation and a test set. For that, we define a LightningDataModule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class to handle our data more easily\n",
    "class ImgDataset:\n",
    "    def __init__(self, dirpath_images:str, img_transform:torch.nn.Module, labels, ) -> None:\n",
    "        self.imgs_path = dirpath_images\n",
    "        self.tf = img_transform\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.tf(self.imgs_path[index]), {   \n",
    "            'id':int(os.path.basename(self.imgs_path[index]).split('.')[0]),\n",
    "            'label':self.labels[index],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "torch.manual_seed(243)\n",
    "\n",
    "class FullImageSudokuDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Data module for Visual Sudoku Solver\n",
    "\n",
    "    Expect data to be in the following format: \n",
    "        data_dir\n",
    "\n",
    "        ├── img\n",
    "\n",
    "        │   ├── 001.png\n",
    "\n",
    "        │   └── 002.png\n",
    "\n",
    "        ├── label\n",
    "\n",
    "        │   ├── 001.npy\n",
    "\n",
    "        │   └── 002.npy\n",
    "\n",
    "        where \n",
    "\n",
    "        Args:\n",
    "            data_dir (str, optional): path to data. Defaults to '.'.\n",
    "            img_transform (nn.Module, optional): preprocessing pipeline. Defaults to the Identity function.\n",
    "            train_batch_size (int, optional): batch size during training. Defaults to 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir:str = '.', img_transform:torch.nn.Module=torch.nn.Identity(), train_batch_size=1) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = Path(data_dir).resolve()\n",
    "        self.train_batch_size = train_batch_size\n",
    "        assert (self.data_dir / 'img').is_dir(), f'bad data format, {data_dir}/img'\n",
    "        assert (self.data_dir / 'label').is_dir(), f'bad data format, {data_dir}/label'\n",
    "        self.img_transforms = img_transform\n",
    "        self.imgs_fname = [os.path.join(self.data_dir,'img',n) for n in sorted(os.listdir(self.data_dir / 'img'), key=lambda n:int(n.split('.')[0]))]\n",
    "        self.labels = np.array([np.load(os.path.join(self.data_dir,'label',l)) for l in sorted(os.listdir(self.data_dir / 'label'), key=lambda n:int(n.split('.')[0]))])\n",
    "        \n",
    "        # train val test split\n",
    "        n_train = 72\n",
    "        n_val = 11\n",
    "        n_test = len(self.imgs_fname) - n_train - n_val\n",
    "        self.train_subset, self.val_subset, self.test_subset = torch.utils.data.random_split(np.arange(len(self.labels)), [n_train, n_val, n_test])\n",
    "        self.img_dataset = ImgDataset(self.imgs_fname, self.img_transforms, torch.from_numpy(self.labels))\n",
    "    \n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(Subset(self.img_dataset, self.train_subset.indices), batch_size=1, shuffle=False)\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        # batch size could be increase here\n",
    "        return DataLoader(Subset(self.img_dataset, self.train_subset.indices), batch_size=self.train_batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(Subset(self.img_dataset, self.train_subset.indices), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use lightning to train and evaluate our architecture. \n",
    "\n",
    "Wrapping our CNN into a LightningModule enriches it with useful features, thus reducing the amount of glue code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "class FullImageCNNLightning(pl.LightningModule):\n",
    "    \"\"\" Wrapper for Full Image Sudoku CNN module\n",
    "    \"\"\"\n",
    "    def __init__(self, cnn: nn.Module, lr=1e-2, num_pred_classes=10, puzzle_shape=(9, 9), hparams=dict()):\n",
    "        super().__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lr = lr \n",
    "        self.num_pred_classes = num_pred_classes\n",
    "        self.puzzle_shape = puzzle_shape\n",
    "        self.save_hyperparameters(\"lr\",  \"num_pred_classes\", hparams)\n",
    "\n",
    "    def forward(self, x,):\n",
    "        cnn_output = self.cnn(x)\n",
    "        return cnn_output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        loss = 0\n",
    "        cnn_output = self(x)\n",
    "        loss_dict = self.compute_loss(cnn_output, target)\n",
    "        loss += torch.stack([v for v in loss_dict.values()]).mean() \n",
    "        return loss\n",
    "\n",
    "    def compute_loss(self, cnn_output:dict, target) -> dict:\n",
    "        target_dim = target['label'].flatten().shape\n",
    "        # cross entropy loss (binary form) \n",
    "        weighted_bce = torch.nn.BCELoss()\n",
    "        cell_value_loss = weighted_bce(\n",
    "            cnn_output['predictions'].view(*target_dim, -1), torch.eye(self.num_pred_classes)[target['label'].flatten()]\n",
    "        )\n",
    "        return {\n",
    "            'cell_value_cross_entropy': cell_value_loss\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_eval(batch, batch_idx, testing=False)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_eval(batch, batch_idx, testing=True)\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, log=True, testing=False):\n",
    "        x, target = batch\n",
    "        cnn_output = self(x)\n",
    "        eval_output = dict()\n",
    "        str_eval_type = 'test' if testing else 'val'\n",
    "        \n",
    "        target_shape = target['label'].flatten().shape\n",
    "        labels_reduce = target['label'].reshape(*target_shape)\n",
    "        pred = torch.argmax(\n",
    "                cnn_output['predictions'].reshape(\n",
    "                    *target_shape, -1), -1).long()\n",
    "        \n",
    "        eval_output[f'{str_eval_type}_cell_accuracy'] = (\n",
    "            pred == labels_reduce).sum() / pred.numel()\n",
    "        \n",
    "        # per-label accuracy\n",
    "        for l in torch.arange(10):\n",
    "            idx = labels_reduce == l\n",
    "            per_cell_acc = (pred[idx] == labels_reduce[idx]\n",
    "                            ).sum() / labels_reduce[idx].numel()\n",
    "            if labels_reduce[idx].numel() != 0:\n",
    "                eval_output[f'{str_eval_type}_cell_accuracy_{l.item()}'] = per_cell_acc\n",
    "            else:\n",
    "                # lead to NaNs\n",
    "                pass\n",
    "        \n",
    "        for k,v in eval_output.items():\n",
    "            self.log(k, v, prog_bar= True,\n",
    "                on_step=False, on_epoch=True, )\n",
    "        return eval_output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # we will use a variant of the ADAM optimizer\n",
    "        optimizer = torch.optim.AdamW(self.cnn.parameters(), lr=self.lr)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only remaining step is to use the Trainer, provided by lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "# Early Stopping strategy: monitor the accuracy and stop the training if it does not increase over a number of epochs\n",
    "es = EarlyStopping('val_cell_accuracy', mode='max', patience=hyperparams['early_stopping_patience'])\n",
    "\n",
    "logger = CSVLogger(\n",
    "        save_dir='log/',\n",
    "        name='neural_network_p2',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger = logger,\n",
    "    # maximum amount of epochs \n",
    "    max_epochs=hyperparams['max_total_epochs'], \n",
    "    log_every_n_steps=5,\n",
    "    inference_mode=False,\n",
    "    callbacks=[es],\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "data_module = FullImageSudokuDataModule(\n",
    "    os.path.join('data', 'visual_sudoku/'), \n",
    "    base_tsfm, \n",
    "    train_batch_size=hyperparams['train_batch_size'] # number of images per batch, during training\n",
    ")\n",
    "\n",
    "print('instances in test set:', data_module.test_subset.indices)\n",
    "\n",
    "ml_model = FullImageCNNLightning(\n",
    "    full_image_cnn,\n",
    "    lr=hyperparams['learning_rate'], # learning rate for the gradient-based update\n",
    "    num_pred_classes=10, \n",
    "    puzzle_shape=(9,9), \n",
    "    hparams=hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use the trainer for Training, Validaiton and Testing\n",
    "trainer.validate(ml_model,datamodule=data_module)\n",
    "trainer.fit(ml_model, datamodule=data_module)\n",
    "trainer.test(ml_model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = os.path.join(trainer.logger.root_dir, f'version_{trainer.logger.version}')\n",
    "checkpoint_path = os.path.join(saved_path,'checkpoints')\n",
    "print('your model was saved in ', os.path.join(saved_path, 'checkpoints', os.listdir(checkpoint_path)[0]))\n",
    "print('Version number : ',trainer.logger.version )\n",
    "print('see hyperparameters values in ', os.path.join(saved_path, 'hparams.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load weights of a pre-trained CNN\n",
    "from collections import OrderedDict\n",
    "def load_from_checkpoint(version_id=0):\n",
    "    cnn = FullImageCNN()\n",
    "    dir_chkp_path = os.path.join('log', 'neural_network_p1', f'version_{version_id}', 'checkpoints')\n",
    "    chkp_path = os.path.join(dir_chkp_path, os.listdir(dir_chkp_path)[0])\n",
    "    CKPT_state_dict = torch.load(chkp_path)\n",
    "    layer_names = list(cnn.state_dict().keys())\n",
    "    to_load = OrderedDict(**{k.split('cnn.')[1]:v for k,v in CKPT_state_dict['state_dict'].items() if k.split('cnn.')[1] in layer_names})\n",
    "    cnn.load_state_dict(to_load)\n",
    "    return cnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(probs, cell_idx, imgtitle=\"\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = probs.numpy().squeeze()[cell_idx]\n",
    "    # fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    fig, ax2 = plt.subplots(1,1, figsize=(6,6))\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(['empty'] + np.arange(1,10).tolist())\n",
    "    ax2.set_title(f'Class Probability {cell_idx}')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "@torch.no_grad() # disable gradients computation\n",
    "def show_one_prediction(cnn, torch_image, cell_idx):\n",
    "    output = cnn(torch_image.unsqueeze(0)) # add a batch dimension\n",
    "    view_classify(output['predictions'].reshape(9,9,-1), cell_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(6,9))\n",
    "axes[0].imshow(original)\n",
    "axes[0].set_title('original image')\n",
    "# This is what the neural network actually sees\n",
    "axes[1].imshow(see_torch_image(image_preprocessed))\n",
    "axes[1].set_title('preprocessed image')\n",
    "for ax in axes:\n",
    "    ax.set_axis_off()\n",
    "show_one_prediction(full_image_cnn, image_preprocessed, (6,2)) # change indices of the cell you want to see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sudoku_model, solve_sudoku\n",
    "\n",
    "@torch.no_grad() # disable gradient computation\n",
    "def get_predictions(cnn, image_preprocessed): \n",
    "    output = cnn(image_preprocessed.unsqueeze(0))['predictions']\n",
    "    return output.detach().squeeze().numpy().reshape(9,9,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our CNN outputs a probability tensor of size 9 x 9 x 10, representing the distribution over possible values for each cell. By taking the `argmax` probability for each cell, we obtain the class assigned by the CNN for the cell. \n",
    "\n",
    "We can use these argmax classes as input for our basic sudoku solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ml_predictions = get_predictions(full_image_cnn, image_preprocessed)\n",
    "ml_instance = ml_predictions.argmax(-1)\n",
    "sudoku_problem = get_sudoku_model(ml_instance)\n",
    "results = solve_sudoku(sudoku_problem['model'], sudoku_problem['variables'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a high accuracy (>95%), our CNN may still make prediction errors. Those errors may lead to an infeasible sudoku.\n",
    "Let's see how many sudoku are: \n",
    "1. solved (solver finds a feasible solution)\n",
    "2. solved **correctly** (the solution found corresponds to the true solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpmpy.solvers.solver_interface import ExitStatus\n",
    "# here is a loop over test instances \n",
    "test_set = [6, 35, 91, 96, 10, 80, 11, 72, 51, 20, 75, 82, 21, 4, 41, 14, 88, 56, 79, 94]\n",
    "\n",
    "count_unsat = 0 \n",
    "count_solved = 0\n",
    "\n",
    "for instance_id in test_set:\n",
    "    img_path = os.path.join('data', 'visual_sudoku', 'img', f'{instance_id:03d}.jpg')\n",
    "    label_path = os.path.join('data', 'visual_sudoku', 'label', f'{instance_id:03d}.npy')\n",
    "    label = np.load(label_path)\n",
    "    # preprocessing\n",
    "    img_preprocessed = base_tsfm(img_path)\n",
    "    # machine learning predictions\n",
    "    ml_predictions = get_predictions(full_image_cnn, img_preprocessed)\n",
    "    # argmax to get predicted puzzle \n",
    "    ml_instance = ml_predictions.argmax(-1)\n",
    "    # solve sudoku \n",
    "    sudoku_problem = get_sudoku_model(ml_instance)\n",
    "    results = solve_sudoku(sudoku_problem['model'], sudoku_problem['variables'])\n",
    "    # evaluate the status \n",
    "    if results['status'] == ExitStatus.UNSATISFIABLE:\n",
    "        count_unsat += 1\n",
    "    # get the true solution using labels as starting clues\n",
    "    sudoku_problem = get_sudoku_model(label)\n",
    "    ground_truth = solve_sudoku(sudoku_problem['model'], sudoku_problem['variables'])\n",
    "    # every cell in ground truth should match with cell in our result\n",
    "    if np.all(ground_truth['solution'] == results['solution']):\n",
    "        count_solved += 1\n",
    "print(f'Rate of infeasible puzzles: {count_unsat/len(test_set):2%}')\n",
    "print(f'Rate of correctly solved puzzles: {count_solved/len(test_set):2%}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play a bit!\n",
    "\n",
    "**Try to improve the accuracy of your neural network by trying out different hyperparameter values!**\n",
    "\n",
    "Change values in the ´hyperparams´ dictionary at the begining and just restart the notebook. Each of your trained CNNs is saved in the ´log´ folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains advanced challenges, feel free to try them out at the end of the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Challenge] Handling Data Imbalance\n",
    "\n",
    "Our dataset contains 103 Visual Sudoku instances. Each Sudoku image is of size 300x300, in color, aligned, and well centered. Some are blurry, riddled with creases or other visual artifacts. Some contains handwritten digits, others are slightly shifted or rotated, etc.\n",
    "\n",
    "<img src=\"data/visual_sudoku/img/073.jpg\" alt=\"sudoku\" style=\"width: 400px;\"/>\n",
    "\n",
    "Unlike numerical instances that solver can handle directly, these require to interpret the image first. Therefore, we want to train a neural network to infer the content of sudoku grid. This network should learn to predict values for all cells, whether they are empty or contain a starting clue. \n",
    "\n",
    "As such, this task can be viewed as a multioutput classification problem. From a given image, our machine learning should classify 81 cells. Each cell label $\\in \\{empty,1,\\ldots,9\\}$\n",
    "\n",
    "Let's visualize the distribution of labels in the dataset.\n",
    "\n",
    "<img src=\"assets/imbalance.png\" alt=\"imbalance\" style=\"width: 400px;\"/>\n",
    "\n",
    "The `empty` class is way more prevalent than others. This imbalance in the data can hinder the learning process if not handle carefully.\n",
    "\n",
    "**Task: There exists many methods to handle data imbalance, but all of them may not be practical. One of them consists of assigning different weights to samples when computing the training loss, depending on the inverse popularity of their class in the current batch.**\n",
    "Does it have any impact on the overall accuracy? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Challenge] Printed and Handwritten (part 1)\n",
    "\n",
    "As you may have notice, some images contains both printed and handwritten digits. \n",
    "We can assume that, as printed value genrally make up the starting clues of the puzzle, they are more reliable than handwritten values provided by a player.\n",
    "\n",
    "<img src=\"data/visual_sudoku/img/030.jpg\" alt=\"sudoku\" style=\"width: 400px;\"/>\n",
    "\n",
    "A smart hybrid CP-ML solver could exploit this information to improve its rate of correctly solved instances. \n",
    "The fist step towards design such system is to build a machine learning architecture capable of predicting both the value of a cell and its font style (printed or handwritten). \n",
    "\n",
    "This can be framed as a *multitask classification problem*. A simple work around is to train an additional machine learning estimator solely for font style classification.\n",
    "However, there exists multiple ways to change the current neural network architecture to handle such a problem. \n",
    "\n",
    "**Task: train a modified CNN that can predict both cell value and font style.**\n",
    "\n",
    "*Tip: we provide additional labels about font style for each cell, in `data/visual_sudoku/style` folder. You can edit the `ImgDataset` class to also provides such labels during training* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class to handle our data more easily\n",
    "class ImgDatasetStyle:\n",
    "    def __init__(self, dirpath_images:str, img_transform:torch.nn.Module, labels, styles) -> None:\n",
    "        self.imgs_path = dirpath_images\n",
    "        self.tf = img_transform\n",
    "        self.labels = labels\n",
    "        self.styles = styles\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.tf(self.imgs_path[index]), {   \n",
    "            'id':int(os.path.basename(self.imgs_path[index]).split('.')[0]),\n",
    "            'label':self.labels[index],\n",
    "            'label_style':self.styles[index],\n",
    "        }\n",
    "\n",
    "class FullImageSudokuStyleDataModule(FullImageSudokuDataModule):\n",
    "    def __init__(self, data_dir:str = '.', img_transform:torch.nn.Module=torch.nn.Identity(), train_batch_size=1) -> None:\n",
    "        super().__init__(datadir, img_transform, train_batch_size)\n",
    "        self.labels_style = np.array([np.load(os.path.join(self.data_dir,'style',l)) for l in sorted(os.listdir(self.data_dir / 'style'), key=lambda n:int(n.split('.')[0]))])\n",
    "        self.img_dataset = ImgDataset(self.imgs_fname, self.img_transforms, torch.from_numpy(self.labels), torch.from_numpy(self.labels_style))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, style labels are available in `compute_loss` function at `target['label_style]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
