{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import cpmpy as cp\n",
    "from cpmpy.solvers import CPM_ortools\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Solving a Sudoku with CPMpy\n",
    "\n",
    "A previous notebook covered ways to model the basic Sudoku problem in CP and solve it, using CPMpy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sudoku_model(n=9):\n",
    "    b = np.sqrt(n).astype(int)\n",
    "    cells = cp.IntVar(1, n, shape=(n,n))\n",
    "\n",
    "    # plain sudoku model\n",
    "    m = cp.Model(\n",
    "        [cp.alldifferent(row) for row in cells],\n",
    "        [cp.alldifferent(col) for col in cells.T],\n",
    "        [cp.alldifferent(cells[i:i + b, j:j + b])\n",
    "            for i in range(0, n, b) for j in range(0, n, b)],\n",
    "    )\n",
    "    return {\n",
    "        'model':m,\n",
    "        'variables':cells\n",
    "    }\n",
    "\n",
    "def solve_sudoku(model, dvars, instance):\n",
    "    # use another object for solving\n",
    "    newmodel = cp.Model(model.constraints) \n",
    "    # set given clues\n",
    "    newmodel += cp.all(instance[instance>0] == dvars[instance>0])\n",
    "    if newmodel.solve():\n",
    "        results = {\n",
    "            'runtime':np.asarray(newmodel.cpm_status.runtime),\n",
    "            'solution':dvars.value(),\n",
    "        }\n",
    "    else:\n",
    "        results = {\n",
    "            'solution':np.full_like(dvars.value(), np.nan)\n",
    "        }\n",
    "    results['status'] = np.asarray(newmodel.cpm_status.exitstatus.value)\n",
    "    return results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Sudoku\n",
    "\n",
    "![](data/visual_sudoku/img/059.jpg) \n",
    "\n",
    "In this variant, the input is now a image of a cropped Sudoku grid, sample from the [Sudoku Assistant App](https://visualsudoku.cs.kuleuven.be/).\n",
    "\n",
    "Solving a visual Sudoku instance requires an approach combining Machine Learning and Constraint Solving. Many of such hybrid system have been proposed in recent years. We will focus on an extension of our work on the topic. (see our [relevant paper](https://link.springer.com/chapter/10.1007/978-3-030-58942-4_24))\n",
    "\n",
    "We want to find the **maximum likelihood** assignement of decision variables. This means adding an objective function: a weighted sum over decision variables, using as weight log-probabilies provided by a neural network. \n",
    "\n",
    "But we cannot directly use our usual Sudoku decision variables to define this objective function, because of a mismatch between their domain ($\\{1,\\ldots, 9\\}$) and machine learning classes $\\in \\{empty, 1, \\ldots, 9\\}$. Hence, we introduce a new set of *perception variables* that acts as an interface layer. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notable differences with the previous setting: \n",
    "- No given clues: we have to rely on (probabilistic) output of the machine learning model to infer the value (or the absence of) for each cell\n",
    "- The machine learning model should learn to classify empty cells, while domains of our decision variables are [1, ..., 9]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_sudoku_full_image_model(ml_predictions, precision=1e-5):\n",
    "    # base model and decision variables \n",
    "    visual_sudoku_problem = get_sudoku_model()\n",
    "    model = visual_sudoku_problem['model']\n",
    "    decision_variables = visual_sudoku_problem['variables']\n",
    "    # introduce a layer of 'perception' variables, as an interface\n",
    "    # between the solver and the ml network\n",
    "    # their domain is [0, ..., 9], with 0 acting as the 'empty' symbol\n",
    "    perception_variables = cp.intvar(0, 9, shape=decision_variables.shape, name='perception')\n",
    "\n",
    "    # convert predictions to logspace\n",
    "    logprobs = np.log(np.maximum( ml_predictions, precision ))\n",
    "    # cp solver requires integer values\n",
    "    logprobs = np.array(logprobs / precision).astype(int)\n",
    "    # switch to cpm_array for more features\n",
    "    logprobs = cp.cpm_array(logprobs)\n",
    "    # build the objective function over perception variables \n",
    "    objective_function = sum(logprobs[idx][v] for idx,v in np.ndenumerate(perception_variables))\n",
    "    model.maximize(objective_function)\n",
    "    \n",
    "    # channeling constraints to link decision variables to perception variables\n",
    "    # perception variable is either 'empty' or matches grid symbol\n",
    "    model+= [(perception_variables != 0).implies(decision_variables == perception_variables)]\n",
    "    # keep track of perception variables as well \n",
    "    visual_sudoku_problem['perception'] = perception_variables\n",
    "    return visual_sudoku_problem\n",
    "\n",
    "def solve_visual_sudoku_full_image(visual_sudoku_problem, solver_params=dict()):\n",
    "    model = visual_sudoku_problem['model']\n",
    "    dvars, pvars = visual_sudoku_problem['variables'], visual_sudoku_problem['perception']\n",
    "    s = CPM_ortools(model)\n",
    "    if s.solve(**solver_params):\n",
    "        results = {\n",
    "            'solution':dvars.value(),\n",
    "            'perception':pvars.value()\n",
    "        }\n",
    "    else:\n",
    "        # in case of infeasibility, nan\n",
    "        results = {\n",
    "            'solution':np.full_like(dvars.value(), np.nan),\n",
    "            'perception':np.full_like(dvars.value(), np.nan)\n",
    "        }\n",
    "    results['status'] = np.asarray(s.cpm_status.exitstatus.value)\n",
    "    results['runtime'] = np.asarray(s.cpm_status.runtime)\n",
    "    return results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the search space\n",
    "\n",
    "Adding a cost function turns the Sudoku into a constrained optimization problem. As the solver now reasons over probability distributions for all cells, we expect the solving of a visual sudoku instance to be slower. \n",
    "\n",
    "**Task: alleviate this issue by constraining the solver to only use the top-k best predictions for each cells**\n",
    "\n",
    "*Tip: this could be easily implemented with a [cp.expressions.InDomain](https://cpmpy.readthedocs.io/en/latest/api/expressions/globalconstraints.html#cpmpy.expressions.globalconstraints.InDomain) constraint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_topk_constraint(model, perception_variables, ml_predictions, k=9): \n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should match the values for your pre-trained CNN\n",
    "hyperparams = {\n",
    "    # preprocessing\n",
    "    'size':(300,300),\n",
    "    # architecture\n",
    "    'dropout':0.25,\n",
    "    'batchnorm':True,\n",
    "    'pooling_kernel_size':3,\n",
    "    'pooling_stride':3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_conv_layers, make_fc_layers_global_pooling\n",
    "import torchvision.transforms as T \n",
    "from torchvision.io import read_image\n",
    "\n",
    "base_tsfm = T.Compose([\n",
    "    T.Lambda(lambda img_str:read_image(img_str)),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(hyperparams['size']), # scale down image here to speed up training\n",
    "    T.ToTensor(),\n",
    "    T.Normalize( # Normalize the data (all values between -1 and 1) to improve convergence\n",
    "        mean=[0.5320, 0.5209, 0.5204],\n",
    "        std=[0.1862917, 0.19031495, 0.18998064]\n",
    "    ), \n",
    "    #T.Grayscale(1) # grayscale the image\n",
    "])\n",
    "\n",
    "class FullImageCNN(nn.Module):\n",
    "    \"\"\"Generalized 5-layers CNN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_shape=(9, 9), n_classes=10) -> None:\n",
    "        super().__init__()\n",
    "        self.grid_shape = grid_shape\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # backbone with 5 convolutional layers\n",
    "        # This should also match with layers in your pre-trained CNN\n",
    "        full_image_backbone_config = [\n",
    "            (32, 4, 2, 0),\n",
    "            (64, 3, 2, 0), \n",
    "            (128, 3, 2, 0), \n",
    "            (256, 2, 2, 0), \n",
    "            (512, 2, 2, 0), \n",
    "        ]\n",
    "\n",
    "        conv_layers = make_conv_layers(\n",
    "            full_image_backbone_config, \n",
    "            in_channels=3, # number of channel in the input image (3 for RGB, 1 for grayscale)\n",
    "            p=hyperparams['dropout'], # dropout rate\n",
    "            pool_ks=hyperparams['pooling_kernel_size'], \n",
    "            pool_str=hyperparams['pooling_stride'], \n",
    "            batch_norm=hyperparams['batchnorm'] # controls whether to add batchnorm in-between convolutional layers\n",
    "        )\n",
    "        # because of the last convolutional layer, this backbone output a tensor whose first dimension is of size 512\n",
    "        self.feat_extract = nn.Sequential( *conv_layers)\n",
    "\n",
    "        # classifier\n",
    "        out_layers = make_fc_layers_global_pooling(\n",
    "            in_dim=512, # this should match with the size of first dimension of the previous layer (hence 512)\n",
    "            out_shape=grid_shape, \n",
    "            num_classes=n_classes\n",
    "        )\n",
    "        self.classifier = nn.Sequential(*out_layers,  nn.Softmax(-1))\n",
    "        # the output is of size 81 x 10 \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.feat_extract(x)\n",
    "        return {\n",
    "            'predictions': self.classifier(h)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load weights of a pre-trained CNN\n",
    "def load_from_checkpoint(version_id=0):\n",
    "    cnn = FullImageCNN()\n",
    "    dir_chkp_path = os.path.join('log', 'neural_network_p2', f'version_{version_id}', 'checkpoints')\n",
    "    chkp_path = os.path.join(dir_chkp_path, os.listdir(dir_chkp_path)[0])\n",
    "    CKPT_state_dict = torch.load(chkp_path)\n",
    "    layer_names = list(cnn.state_dict().keys())\n",
    "    to_load = OrderedDict(**{k.split('cnn.')[1]:v for k,v in CKPT_state_dict['state_dict'].items() if k.split('cnn.')[1] in layer_names})\n",
    "    cnn.load_state_dict(to_load)\n",
    "    return cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_cnn = load_from_checkpoint(0)\n",
    "pretrained_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get predictions from our pre-trained CNN\n",
    "@torch.no_grad() # disable gradient computation\n",
    "def get_predictions(cnn, image_preprocessed): \n",
    "    output = cnn(image_preprocessed.unsqueeze(0))['predictions']\n",
    "    return output.detach().squeeze().numpy().reshape(9,9,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join('data', 'visual_sudoku', 'img', '059.jpg')\n",
    "original = Image.open(img_path)\n",
    "\n",
    "see_torch_image = T.ToPILImage()\n",
    "image_preprocessed = base_tsfm(img_path)\n",
    "ml_predictions = get_predictions(pretrained_cnn, image_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a high accuracy (>95%), our CNN may still make prediction errors. Those errors may lead to an infeasible sudoku. \n",
    "This issue is directly addressed in the *visual sudoku solver*. Reasoning over probabilities enables the solver to sometimes correct neural network mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual sudoku cp model\n",
    "visual_sudoku_problem = get_visual_sudoku_full_image_model(ml_predictions)\n",
    "# top-k?\n",
    "post_topk_constraint(visual_sudoku_problem['model'], visual_sudoku_problem['perception'], ml_predictions)\n",
    "# solve \n",
    "results = solve_visual_sudoku_full_image(visual_sudoku_problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show solution\n",
    "from utils import visu_sudoku\n",
    "original = Image.open(img_path)\n",
    "display(original)\n",
    "visu_sudoku(results['solution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution looks good. However, it needs to be properly evaluated. To do so, it is enough to compare the value of cells containing starting clues, with values of the same cells in our solution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also observe values of perception variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_sudoku(results['perception'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it with the original to identify neural network mistakes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Evaluate the performance of your pre-trained neural network on the sudoku solving task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a loop over test instances \n",
    "test_set = [6, 35, 91, 96, 10, 80, 11, 72, 51, 20, 75, 82, 21, 4, 41, 14, 88, 56, 79, 94]\n",
    "count_unsat = 0\n",
    "count_solved = 0\n",
    "for instance_id in test_set:\n",
    "    img_path = os.path.join('data', 'visual_sudoku', 'img', f'{instance_id:03d}.jpg')\n",
    "    label_path = os.path.join('data', 'visual_sudoku', 'label', f'{instance_id:03d}.npy')\n",
    "    label = np.load(label_path)\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Challenge] Higher-order knowledge exploitation\n",
    "\n",
    "Because of the added objective function our visual Sudoku problem became an optimisation problem, which may have many feasible solutions.\n",
    "\n",
    "However, any valid sudoku puzzle only admits a *unique solution* for a set of givens. To improve the efficiency of our hybrid approach, we can actually exploit this uniqueness property in the following manner:\n",
    "- When the solver finds optimal solution, add the resulting assignment as a no-good (i.e. forbid it) and try to solve again\n",
    "- if any feasible solution is found this way, previous assignment for given cells does not lead to unique solution\n",
    "\n",
    "Iterate these steps until the uniqueness property is satisfied. \n",
    "\n",
    "In practice, we may need to loop several times depending on the accuracy of the classifier.\n",
    "\n",
    "**Task implement the higher-order knowledge exploitation method. You can start from the helper code below**\n",
    "\n",
    "*Tip: you can forbid an assignement of variables by doing* \n",
    "```python\n",
    "model += [~cp.all((perception_variables ==  perception_variables.value())) ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_visual_sudoku_higher_order(visual_sudoku_problem, solver_params=dict(), max_iter=100):\n",
    "    results = solve_visual_sudoku_full_image(visual_sudoku_problem, solver_params)\n",
    "    #Write a loop repeating following steps:\n",
    "    # while results['solution'] is not unique or iteration < max_iter:\n",
    "    #   add nogood to the vizsudoku model\n",
    "    #   solve again\n",
    "    #   iteration += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Challenge] Printed and Handwritten digits (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have notice, some images contains both printed and handwritten digits. \n",
    "We can assume that, as printed value genrally make up the starting clues of the puzzle, they are more reliable than handwritten values provided by a player.\n",
    "\n",
    "<img src=\"data/visual_sudoku/img/030.jpg\" alt=\"sudoku\" style=\"width: 400px;\"/>\n",
    "\n",
    "A smart hybrid CP-ML solver could exploit this information to improve its rate of correctly solved instances. \n",
    "\n",
    "Assuming that your CNN provides for each cell: \n",
    "1. the probability distribution over possible values (as a 9x9x10 tensor)\n",
    "2. the probability that it contains a printed digit (as a 9 x 9 matrix)\n",
    "\n",
    "**Task: implement a new `get_visual_sudoku_full_image_model` that accepts two sets of ML predictions described above. There are many ways to integrate them into the model (through the objective function). Do you observe any gain in performance? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
